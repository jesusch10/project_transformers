# Advanced Large Language Models (LLMs):

This repository documents my hands-on learning journey in building and understanding Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, and Transformer-based architectures. It includes both foundational implementations and practical applications using state-of-the-art tools and libraries.

The work is inspired and guided by the following key learning resources:

- [**LLM Course** by Hugging Face](https://huggingface.co/learn/llm-course/)
- [**Generative AI with Large Language Models Course** by AWS](https://www.coursera.org/learn/generative-ai-with-llms)
- [**Sequence Models Course** by DeepLearning.AI](https://www.coursera.org/learn/nlp-sequence-models), part of the **Deep Learning Specialization**

## 📁 Structure

```bash
📂 dinosaurus_model_from_scratch/
    └── RNN model from scratch to generate new dinosaurus names
📂 jazz_model_from_keras/
    └── LSTM model using Keras to generate Jazz music
📂 hugging_ecosystem_usage/
    ├── chap1-pretrained_LLM.ipynb
    ├── chap2-autotokenizers_and_automodels.ipynb
    ├── chap3-fine_tune_basic.ipynb
    ├── chap4-5-manage_data.ipynb
    ├── chap6-create_tokenizers.ipynb
    ├── chap7-prompt_engineering.ipynb
    ├── chap7-training_models.ipynb
    ├── chap8-fine_tune_advanced.ipynb
    └── chap9-detoxifying_models.ipynb
