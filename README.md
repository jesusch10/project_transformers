# Advanced Large Language Models (LLMs):

This repository documents my hands-on learning journey in building and understanding Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, and Transformer-based architectures. It includes both foundational implementations and practical applications using state-of-the-art tools and libraries.

The work is inspired and guided by the following key learning resources:

- [**LLM Course** by Hugging Face](https://huggingface.co/learn/llm-course/)
- [**Generative AI with Large Language Models Course** by AWS](https://www.coursera.org/learn/generative-ai-with-llms)
- [**Sequence Models Course** by DeepLearning.AI](https://www.coursera.org/learn/nlp-sequence-models), part of the **Deep Learning Specialization**
- [**OCI Generative AI Professional Course** by Oracle University](https://learn.oracle.com/ols/learning-path/become-an-oci-generative-ai-professional-2025/118071/147863)

## ğŸ“ Structure

```bash
ğŸ“‚ LLMs_models_from_hugging_ecosystem/
    â””â”€â”€ I summarized the Transformers and Hugging Face workflows to train, fine-tune, and manage LLMs
ğŸ“‚ dinosaurus_model_from_scratch/
    â””â”€â”€ I created a RNN model from scratch to generate new dinosaurus names
ğŸ“‚ jazz_model_from_keras/
    â””â”€â”€ I created a LSTM model using Keras to generate Jazz music
ğŸ“‚ RAG_chatbot_model_from_oracle/
    â””â”€â”€ I implemented a RAG chatbot with Oracle 23ai and LangChain to query a PDF
ğŸ“‚ transformer_model_from_tensorflow/
    â””â”€â”€ I built the Transformer architecture using TensorFlow ready for training

